{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Lab 3 â€’  Classification\n",
    "\n",
    "\n",
    "**Group ID:** 45\n",
    "\n",
    "**Author 1 (sciper):** Elias William (367106)  \n",
    "**Author 2 (sciper):** Erik Kvikne (360962)   \n",
    "**Author 3 (sciper):** Sami Laubo (360965)  \n",
    "\n",
    "**Release date:** 19.04.2023  \n",
    "**Due date:** 05.05.2023 \n",
    "\n",
    "\n",
    "## Important notes\n",
    "\n",
    "The lab assignments are designed to teach practical implementation of the topics presented during class well as\n",
    "preparation for the final project, which is a practical project which ties together the topics of the course.\n",
    "\n",
    "As such, in the lab assignments/final project, unless otherwise specified, you may, if you choose, use external\n",
    "functions from image processing/ML libraries like opencv and sklearn as long as there is sufficient explanation\n",
    "in the lab report. For example, you do not need to implement your own edge detector, etc.\n",
    "\n",
    "**! Before handling back the notebook <font color='red'> rerun </font>the notebook from scratch !**\n",
    "`Kernel` > `Restart & Run All`\n",
    "\n",
    "We will not rerun the notebook for you.\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will use PyTorch. If you are not familiar with this library, [here](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html) is a quick tutorial of the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.8.1+cu111 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu113, 1.11.0+cu115, 1.12.0, 1.12.0+cpu, 1.12.0+cu113, 1.12.0+cu116, 1.12.1, 1.12.1+cpu, 1.12.1+cu113, 1.12.1+cu116, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 2.0.0, 2.0.0+cpu, 2.0.0+cu117, 2.0.0+cu118)\n",
      "ERROR: No matching distribution found for torch==1.8.1+cu111\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.system())\n",
    "if platform.system() == \"Darwin\":\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1\n",
    "else:\n",
    "    %pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-03-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 - Out-of-Distribution detection in colorectal cancer histology (12 points)\n",
    "\n",
    "Colorectal cancer is one of the most widespread cancers for men and women. Diagnosis complemented with prognostic and predictive biomarker information is essential for patient monitoring and applying personalized treatments. A critical marker is the tumor/stroma ratio in unhealthy tissues sampled from the colon. The higher the ratio, the more invasive the cancer is. The degree of invasion is tightly linked to patient survial probability.\n",
    "\n",
    "To measure the ratio, a pathologist needs to analyze the unhealthy tissue under a microscope and estimate it from a look. As the number of samples to analyze is huge and estimations are only sometimes precise, automatic recognition of the different tissue types in histological images has become essential. Such an automatic process requires the development of a multi-class classifier to identify the numerous tissues. As shown below, they are usually 8 tissue types to categorize: TUMOR, STROMA, LYMPHO (lymphocytes), MUCOSA, COMPLEX (complex stroma), DEBRIS, ADIPOSE and EMPTY (background).\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"../data/lab-03-data/part1/kather16.svg\" width=\"1100\">\n",
    "    <center>\n",
    "    <figcaption>Fig1: Collection of tissue types in colorectal cancer histology (Kather-16)</figcaption>\n",
    "    </center>\n",
    "</figure>\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "\n",
    "Up to this day, state-of-the-art methods use deep-learning-based supervised learning methods. A downfall of such an approach is the necessity to access a well-annotated training dataset. In histology, annotating data is difficult. It is time-consuming and requires the expertise of pathologists. Moreover, the annotator must label every tissue type while only two (TUMOR and STROMA) are interesting. \n",
    "\n",
    "\n",
    "Consequently, we propose another approach. In order to make the annotation task less tedious, we ask the annotator to label only the tissues of interest and dump the others. Then, we must train a binary classifier to automatically recognize these tissues at test time. In this part, you will implement the proposed approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Binary classifier with Mahalanobis distance (3 points)\n",
    "\n",
    "Based on the abovementioned process, your task is to build a model that recognizes TUMOR (Label 0) and STROMA (Label 1) tissue types. Your model will be supervised by a training dataset containing TUMOR and STROMA annotations; note that all other tissues have been dropped.\n",
    "We will not ask you to train a deep-learning-based binary classifier from scratch. Instead, we provide excellent features (descriptors) of the images we extracted from a visual foundation model. (Note: As the nature of the foundation model is not part of this lecture, feel free to ask TAs if you are curious).\n",
    "\n",
    "Run the cell below to extract the provided train and test dataset. Each image is represented by a 768-d feature vector extracted from a visual foundation model. The train and test datasets contain feature vectors of 878 and 186 images respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([186, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# Label mapping\n",
    "label_to_classname = {0 : \"TUMOR\", 1 : \"STROMA\"}\n",
    "\n",
    "# Train features and labels\n",
    "train_features = torch.load(os.path.join(data_base_path, data_folder, \"part1/k16_train_features.pth\"))\n",
    "train_labels = torch.load(os.path.join(data_base_path, data_folder, \"part1/k16_train_labels.pth\"))\n",
    "\n",
    "# Test features and labels\n",
    "test_features = torch.load(os.path.join(data_base_path, data_folder, \"part1/k16_test_features.pth\"))\n",
    "test_labels = torch.load(os.path.join(data_base_path, data_folder, \"part1/k16_test_labels.pth\"))\n",
    "\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1 (2.5 points)** Based on the training features (```train_features```) and training labels (```train_labels```), classify the test features (```test_features```) using minimum Mahalanobis distance.\n",
    "\n",
    "*Note:* You are not allowed to use any prebuilt Mahalanobis distance function. Additionally, ```torch.cov``` is not defined to compute the covariance matrix. You can use ```sklearn.covariance.LedoitWolf``` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import numpy as np\n",
    "\n",
    "def Mahalanobis_classify(train_features, train_labels, test_features):\n",
    "    # Compute means\n",
    "    mean_zero = torch.mean(train_features[train_labels == 0], 0).numpy()\n",
    "    mean_ones = torch.mean(train_features[train_labels == 1], 0).numpy()\n",
    "\n",
    "    # Compute covariance matrices\n",
    "    covariance_zero = LedoitWolf().fit(train_features[train_labels == 0]).covariance_\n",
    "    covariance_ones = LedoitWolf().fit(train_features[train_labels == 1]).covariance_\n",
    "\n",
    "    covariance_zero_inv = np.linalg.inv(covariance_zero)\n",
    "    covariance_ones_inv = np.linalg.inv(covariance_ones)\n",
    "    \n",
    "    # Predicted classes\n",
    "    pred = np.zeros(test_features.shape[0], dtype=np.int8)\n",
    "\n",
    "    # Compute distance and choose min dist as class\n",
    "    for idx, x in enumerate(test_features.numpy()):\n",
    "        delta = x - mean_zero\n",
    "        dist_zero = np.sqrt(delta @ covariance_zero_inv @ delta.T)\n",
    "\n",
    "        delta = x - mean_ones\n",
    "        dist_ones = np.sqrt(delta @ covariance_ones_inv @ delta.T)\n",
    "\n",
    "        if dist_ones < dist_zero:\n",
    "            pred[idx] = 1\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2 (0.5 points)** Compute the accuracy of your predictions with the test labels (```test_labels```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.978494623655914\n"
     ]
    }
   ],
   "source": [
    "### Task 2\n",
    "\n",
    "test_pred = Mahalanobis_classify(train_features, train_labels, test_features)\n",
    "accuracy = (test_labels == test_pred).sum() / test_labels.shape[0]\n",
    "print(f'{accuracy = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Out-of-Distribution detection with Mahalanobis distance (3 points)\n",
    "\n",
    "You will note that the test you run above is not really realistic. Like the training set, it contains only the TUMOR and STROMA tissue types. Nevertheless, at test time, the other tissues (Label -1) are also present and cannot be filtered by hand. Moreover, they cannot be recognized by the model as they are out of the training distribution (It is the consequence of the laziness of the annotators ;)). For this reason, it is essential to filter them out. This task is called Out-of-Distribution (OoD) detection. \n",
    "\n",
    "A simple way to do OoD detection is to compute for every test example an OoD-ness score which should be low for In-Distribution (ID) examples and high for OoDs. Then we define a threshold from which every example with an OoD-ness lying above is discarded, and those lying below are forwarded to the model for prediction. An example of OoD-ness score is the minimum Mahalanobis distance.\n",
    "\n",
    "Run the cell below to load a new test set containing OoD examples. It has 186 ID and 558 OoD examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([744, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_classname_w_ood = {0 : \"TUMOR\", 1 : \"STROMA\", -1 : \"OoD\"}\n",
    "\n",
    "# Test features and labels with OoD tissues\n",
    "test_features_w_ood = torch.load(os.path.join(data_base_path, data_folder, \"part1/k16_test2_features.pth\"))\n",
    "test_labels_w_ood = torch.load(os.path.join(data_base_path, data_folder,\"part1/k16_test2_labels.pth\"))\n",
    "\n",
    "test_features_w_ood.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1 (0.5 point)** Why do you think the minimum Mahalanobis distance is a good OoD-ness score?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The Mahalanobis distance gives the distance from a point to a distribution. A large covariance leads to a smaller distance, which is intuitive because a large variance in the distribution makes it more likely for a point far away to be a part of the distribution. The minimum Mahalanobis distance takes the smallest distance to any distribution, and if this distance is larger than the threshold we know that the distance to any distribution is larger than our threshold. We can then discard this point as being a part of any distribution if it is above the threshold, saying it's OoD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2 (0.5 point)** Compute the minimum Mahalanobis distance for every test examples in ```test_features_w_ood``` with respect to the training features (```train_features```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2\n",
    "def Mahalanobis_dist(train_features, train_labels, test_features):\n",
    "    # Compute means\n",
    "    mean_zero = torch.mean(train_features[train_labels == 0], 0).numpy()\n",
    "    mean_ones = torch.mean(train_features[train_labels == 1], 0).numpy()\n",
    "\n",
    "    # Compute covariance matrices\n",
    "    covariance_zero = LedoitWolf().fit(train_features[train_labels == 0]).covariance_\n",
    "    covariance_ones = LedoitWolf().fit(train_features[train_labels == 1]).covariance_\n",
    "\n",
    "    covariance_zero_inv = np.linalg.inv(covariance_zero)\n",
    "    covariance_ones_inv = np.linalg.inv(covariance_ones)\n",
    "    \n",
    "    # Predicted classes\n",
    "    Mahal_dist = np.zeros(test_features.shape[0])\n",
    "\n",
    "    # Compute distance and choose min dist as class\n",
    "    for idx, x in enumerate(test_features.numpy()):\n",
    "        delta = x - mean_zero\n",
    "        dist_zero = np.sqrt(delta @ covariance_zero_inv @ delta.T)\n",
    "\n",
    "        delta = x - mean_ones\n",
    "        dist_ones = np.sqrt(delta @ covariance_ones_inv @ delta.T)\n",
    "\n",
    "        Mahal_dist[idx] = np.min([dist_zero, dist_ones])\n",
    "\n",
    "    return Mahal_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3 (0.5 point)** Plot a histogram to show the difference between the Mahalanobis distance of TUMOR, STROMA and OoD tissue types and comment on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Task 3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dists = Mahalanobis_dist(train_features, train_labels, test_features_w_ood)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0, 0].hist(dists[test_labels_w_ood != -1], bins=100)\n",
    "axs[0, 0].set_title('Tumor and Stroma')\n",
    "axs[0, 1].hist(dists[test_labels_w_ood == -1], bins=100)\n",
    "axs[0, 1].set_title('OoD')\n",
    "axs[0, 0].set_xlim([0, 90])\n",
    "axs[0, 1].set_xlim([0, 90])\n",
    "fig.suptitle('Minimal distance histograms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4 (1 point)** Find a threshold on the Mahalanobis distance such that 95% of the OoD examples are filtered out. How much TUMOR and STROMA have also been filtered out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 4\n",
    "### YOUR CODE\n",
    "\n",
    "def find_thres(dists):\n",
    "    # Find threshold by bisection\n",
    "    upper_lim = np.max(dists)\n",
    "    lower_lim = np.min(dists)\n",
    "    thres = (upper_lim + lower_lim)/2\n",
    "    # Goal percentage\n",
    "    goal = 0.95\n",
    "    # Acceptable percentage error\n",
    "    gamma = 0.001\n",
    "    # Percentage of dists that is cut out\n",
    "    dists_thres = dists[dists >= thres]\n",
    "    perc =  dists_thres.size / dists.size\n",
    "    # print(f'Start of algo, thres: {thres}, perc: {perc}')\n",
    "\n",
    "    max_iter = 200\n",
    "    it = 1\n",
    "    # Adjust thres until goal is met\n",
    "    while( np.abs(perc - goal) >= gamma or it < max_iter ):\n",
    "        if perc < goal:\n",
    "            # Lower threshold\n",
    "            # print('Lower the threshold')\n",
    "            upper_lim = thres\n",
    "        else:\n",
    "            # Higher threshold\n",
    "            # print('Increase the threshold')\n",
    "            lower_lim = thres\n",
    "        thres = (upper_lim + lower_lim)/2\n",
    "        # Percentage of dists that is cut out\n",
    "        dists_thres = dists[dists >= thres]\n",
    "        perc =  dists_thres.size / dists.size\n",
    "        # print(f'thres: {thres}, perc: {perc}')\n",
    "        it += it\n",
    "\n",
    "    return thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 30.742215402424335\n",
      "Percentage of iod samples removed: 67.74193548387098\n"
     ]
    }
   ],
   "source": [
    "dist_ood = dists[test_labels_w_ood == -1]\n",
    "thres = find_thres(dist_ood)\n",
    "\n",
    "print(f'Threshold: {thres}')\n",
    "\n",
    "dist_iod = dists[test_labels_w_ood != -1]\n",
    "dist_iod_thres = dist_iod[ dist_iod <= thres ]\n",
    "\n",
    "perc_iod_del = 1 - dist_iod_thres.size / dist_iod.size\n",
    "\n",
    "print(f'Percentage of iod samples removed: {100*perc_iod_del}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5 (0.5 point)** Assign prediction -1 to filtered out examples and compute the average class-wise accuracy of your prediction with test labels (```test_labels_w_ood```). Is it satisfactory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.793010752688172\n"
     ]
    }
   ],
   "source": [
    "### Task 5\n",
    "### YOUR CODE\n",
    "mask_ood = dists > thres\n",
    "pred = Mahalanobis_classify(train_features, train_labels, test_features_w_ood)\n",
    "pred[mask_ood] = -1\n",
    "\n",
    "accuracy = (test_labels_w_ood == pred).sum() / test_labels_w_ood.shape[0]\n",
    "print(f'{accuracy = }')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 80% accuracy. It is not as bad as we thought but many of the tumor/stroma points we know are misclassifed already because of the threshold. So the relatively high accuracy comes from all the OoD samples being correctly classified. If you look at the histograms above we also see that there are many more OoD samples than Tomur/stroma. Which means that these will bias the accuracy to be reltively good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Out-of-distribution detection with k-NN classifier (6 points)\n",
    "\n",
    "The visual foundation models are known to be very good k-NN classifiers. It motivates us to implement a k-NN classifier to recognize TUMOR and STROMA. Moreover, k-NN distance is a good OoD-ness score and suits our task.\n",
    "\n",
    "**Task 1 (2 points)** Based on the training features (```train_features```) and training labels (```train_labels```), classify the test features (```test_features```) using a k-NN classifier. Then report the accuracy of your predictions with the test labels (```test_labels```).\n",
    "\n",
    "*Note:* The choice of `k` is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1\n",
    "### YOUR CODE\n",
    "def knn(train_features, train_labels, test_features, K = 5):\n",
    "    # Train_features (N,D)\n",
    "    # Train_labels (N,)\n",
    "    # Test_features (Nt,D)\n",
    "\n",
    "    test_preds = torch.zeros(test_features.shape[0])\n",
    "\n",
    "    for idx, test_feature in enumerate(test_features):\n",
    "        # Compute distance from test samples to all training samples\n",
    "        delta_features = train_features - test_feature\n",
    "        distances = torch.sqrt(torch.sum(delta_features**2, axis=1))\n",
    "\n",
    "        # Find the K nearest neighbours of this test sample\n",
    "        idx_min_dist = torch.zeros(K)\n",
    "        print(f'Indexes size: {idx_min_dist.shape}')\n",
    "        print(f'Shape of distances: {distances.shape}')\n",
    "\n",
    "        for i in range(K):\n",
    "            # Find nearest neighbour\n",
    "            idx_min = torch.argmin(distances)\n",
    "            idx_min_dist[i] = idx_min\n",
    "            print(f'Index of smallest elem: {idx_min}')\n",
    "            # Remove this neighbour from the list\n",
    "            distances[idx_min] = 1000\n",
    "\n",
    "        # Get labels for these indecise and vote for the most common one\n",
    "        print(f'Min distance indexes {idx_min_dist}')\n",
    "        idx_min_dist = idx_min_dist.numpy().astype(int)\n",
    "        print(f'idx_min_dist: {idx_min_dist}')\n",
    "        near_labels = train_labels[idx_min_dist]\n",
    "        print(f'Shape of near labels: {near_labels.shape} should be K')\n",
    "        print(f'Near labels: {near_labels}')\n",
    "        counts = np.bincount(near_labels)\n",
    "        most_common_label = np.argmax(counts)\n",
    "        print(f'Most common label: {most_common_label}')\n",
    "        test_preds[idx] = most_common_label\n",
    "\n",
    "    return test_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 391\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 362\n",
      "Index of smallest elem: 193\n",
      "Index of smallest elem: 225\n",
      "Min distance indexes tensor([391., 260., 362., 193., 225.])\n",
      "idx_min_dist: [391 260 362 193 225]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 168\n",
      "Index of smallest elem: 135\n",
      "Index of smallest elem: 106\n",
      "Index of smallest elem: 366\n",
      "Index of smallest elem: 267\n",
      "Min distance indexes tensor([168., 135., 106., 366., 267.])\n",
      "idx_min_dist: [168 135 106 366 267]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 98\n",
      "Index of smallest elem: 77\n",
      "Index of smallest elem: 216\n",
      "Index of smallest elem: 4\n",
      "Index of smallest elem: 138\n",
      "Min distance indexes tensor([ 98.,  77., 216.,   4., 138.])\n",
      "idx_min_dist: [ 98  77 216   4 138]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 300\n",
      "Index of smallest elem: 274\n",
      "Index of smallest elem: 336\n",
      "Index of smallest elem: 377\n",
      "Index of smallest elem: 302\n",
      "Min distance indexes tensor([300., 274., 336., 377., 302.])\n",
      "idx_min_dist: [300 274 336 377 302]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 398\n",
      "Index of smallest elem: 29\n",
      "Index of smallest elem: 436\n",
      "Index of smallest elem: 33\n",
      "Index of smallest elem: 56\n",
      "Min distance indexes tensor([398.,  29., 436.,  33.,  56.])\n",
      "idx_min_dist: [398  29 436  33  56]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 45\n",
      "Index of smallest elem: 225\n",
      "Index of smallest elem: 208\n",
      "Index of smallest elem: 193\n",
      "Index of smallest elem: 112\n",
      "Min distance indexes tensor([ 45., 225., 208., 193., 112.])\n",
      "idx_min_dist: [ 45 225 208 193 112]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 75\n",
      "Index of smallest elem: 336\n",
      "Index of smallest elem: 416\n",
      "Index of smallest elem: 120\n",
      "Index of smallest elem: 285\n",
      "Min distance indexes tensor([ 75., 336., 416., 120., 285.])\n",
      "idx_min_dist: [ 75 336 416 120 285]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 204\n",
      "Index of smallest elem: 52\n",
      "Index of smallest elem: 134\n",
      "Index of smallest elem: 414\n",
      "Index of smallest elem: 189\n",
      "Min distance indexes tensor([204.,  52., 134., 414., 189.])\n",
      "idx_min_dist: [204  52 134 414 189]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 188\n",
      "Index of smallest elem: 34\n",
      "Index of smallest elem: 189\n",
      "Index of smallest elem: 221\n",
      "Index of smallest elem: 134\n",
      "Min distance indexes tensor([188.,  34., 189., 221., 134.])\n",
      "idx_min_dist: [188  34 189 221 134]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 134\n",
      "Index of smallest elem: 243\n",
      "Index of smallest elem: 190\n",
      "Index of smallest elem: 390\n",
      "Index of smallest elem: 414\n",
      "Min distance indexes tensor([134., 243., 190., 390., 414.])\n",
      "idx_min_dist: [134 243 190 390 414]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 390\n",
      "Index of smallest elem: 129\n",
      "Index of smallest elem: 273\n",
      "Index of smallest elem: 274\n",
      "Index of smallest elem: 352\n",
      "Min distance indexes tensor([390., 129., 273., 274., 352.])\n",
      "idx_min_dist: [390 129 273 274 352]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 387\n",
      "Index of smallest elem: 394\n",
      "Index of smallest elem: 232\n",
      "Index of smallest elem: 355\n",
      "Index of smallest elem: 288\n",
      "Min distance indexes tensor([387., 394., 232., 355., 288.])\n",
      "idx_min_dist: [387 394 232 355 288]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 376\n",
      "Index of smallest elem: 61\n",
      "Index of smallest elem: 29\n",
      "Index of smallest elem: 288\n",
      "Index of smallest elem: 202\n",
      "Min distance indexes tensor([376.,  61.,  29., 288., 202.])\n",
      "idx_min_dist: [376  61  29 288 202]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 20\n",
      "Index of smallest elem: 407\n",
      "Index of smallest elem: 345\n",
      "Index of smallest elem: 17\n",
      "Index of smallest elem: 85\n",
      "Min distance indexes tensor([ 20., 407., 345.,  17.,  85.])\n",
      "idx_min_dist: [ 20 407 345  17  85]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 416\n",
      "Index of smallest elem: 247\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 400\n",
      "Index of smallest elem: 358\n",
      "Min distance indexes tensor([416., 247., 260., 400., 358.])\n",
      "idx_min_dist: [416 247 260 400 358]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 316\n",
      "Index of smallest elem: 369\n",
      "Index of smallest elem: 195\n",
      "Index of smallest elem: 156\n",
      "Index of smallest elem: 391\n",
      "Min distance indexes tensor([316., 369., 195., 156., 391.])\n",
      "idx_min_dist: [316 369 195 156 391]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 185\n",
      "Index of smallest elem: 396\n",
      "Index of smallest elem: 88\n",
      "Index of smallest elem: 283\n",
      "Index of smallest elem: 358\n",
      "Min distance indexes tensor([185., 396.,  88., 283., 358.])\n",
      "idx_min_dist: [185 396  88 283 358]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 276\n",
      "Index of smallest elem: 270\n",
      "Index of smallest elem: 292\n",
      "Index of smallest elem: 413\n",
      "Index of smallest elem: 400\n",
      "Min distance indexes tensor([276., 270., 292., 413., 400.])\n",
      "idx_min_dist: [276 270 292 413 400]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 391\n",
      "Index of smallest elem: 213\n",
      "Index of smallest elem: 38\n",
      "Index of smallest elem: 156\n",
      "Min distance indexes tensor([260., 391., 213.,  38., 156.])\n",
      "idx_min_dist: [260 391 213  38 156]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 239\n",
      "Index of smallest elem: 436\n",
      "Index of smallest elem: 185\n",
      "Index of smallest elem: 416\n",
      "Index of smallest elem: 117\n",
      "Min distance indexes tensor([239., 436., 185., 416., 117.])\n",
      "idx_min_dist: [239 436 185 416 117]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 193\n",
      "Index of smallest elem: 225\n",
      "Index of smallest elem: 364\n",
      "Index of smallest elem: 429\n",
      "Index of smallest elem: 260\n",
      "Min distance indexes tensor([193., 225., 364., 429., 260.])\n",
      "idx_min_dist: [193 225 364 429 260]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 15\n",
      "Index of smallest elem: 142\n",
      "Index of smallest elem: 50\n",
      "Index of smallest elem: 27\n",
      "Index of smallest elem: 320\n",
      "Min distance indexes tensor([ 15., 142.,  50.,  27., 320.])\n",
      "idx_min_dist: [ 15 142  50  27 320]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 325\n",
      "Index of smallest elem: 394\n",
      "Index of smallest elem: 288\n",
      "Index of smallest elem: 186\n",
      "Index of smallest elem: 201\n",
      "Min distance indexes tensor([325., 394., 288., 186., 201.])\n",
      "idx_min_dist: [325 394 288 186 201]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 334\n",
      "Index of smallest elem: 414\n",
      "Index of smallest elem: 131\n",
      "Index of smallest elem: 116\n",
      "Index of smallest elem: 134\n",
      "Min distance indexes tensor([334., 414., 131., 116., 134.])\n",
      "idx_min_dist: [334 414 131 116 134]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 222\n",
      "Index of smallest elem: 46\n",
      "Index of smallest elem: 72\n",
      "Index of smallest elem: 171\n",
      "Index of smallest elem: 402\n",
      "Min distance indexes tensor([222.,  46.,  72., 171., 402.])\n",
      "idx_min_dist: [222  46  72 171 402]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 17\n",
      "Index of smallest elem: 436\n",
      "Index of smallest elem: 114\n",
      "Index of smallest elem: 381\n",
      "Index of smallest elem: 202\n",
      "Min distance indexes tensor([ 17., 436., 114., 381., 202.])\n",
      "idx_min_dist: [ 17 436 114 381 202]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 393\n",
      "Index of smallest elem: 208\n",
      "Index of smallest elem: 225\n",
      "Index of smallest elem: 45\n",
      "Index of smallest elem: 7\n",
      "Min distance indexes tensor([393., 208., 225.,  45.,   7.])\n",
      "idx_min_dist: [393 208 225  45   7]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 73\n",
      "Index of smallest elem: 221\n",
      "Index of smallest elem: 335\n",
      "Index of smallest elem: 215\n",
      "Index of smallest elem: 191\n",
      "Min distance indexes tensor([ 73., 221., 335., 215., 191.])\n",
      "idx_min_dist: [ 73 221 335 215 191]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 325\n",
      "Index of smallest elem: 17\n",
      "Index of smallest elem: 421\n",
      "Index of smallest elem: 51\n",
      "Index of smallest elem: 82\n",
      "Min distance indexes tensor([325.,  17., 421.,  51.,  82.])\n",
      "idx_min_dist: [325  17 421  51  82]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 60\n",
      "Index of smallest elem: 256\n",
      "Index of smallest elem: 164\n",
      "Index of smallest elem: 435\n",
      "Index of smallest elem: 334\n",
      "Min distance indexes tensor([ 60., 256., 164., 435., 334.])\n",
      "idx_min_dist: [ 60 256 164 435 334]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 370\n",
      "Index of smallest elem: 56\n",
      "Index of smallest elem: 114\n",
      "Index of smallest elem: 374\n",
      "Min distance indexes tensor([260., 370.,  56., 114., 374.])\n",
      "idx_min_dist: [260 370  56 114 374]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 214\n",
      "Index of smallest elem: 421\n",
      "Index of smallest elem: 212\n",
      "Index of smallest elem: 303\n",
      "Index of smallest elem: 228\n",
      "Min distance indexes tensor([214., 421., 212., 303., 228.])\n",
      "idx_min_dist: [214 421 212 303 228]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 285\n",
      "Index of smallest elem: 274\n",
      "Index of smallest elem: 115\n",
      "Index of smallest elem: 336\n",
      "Index of smallest elem: 258\n",
      "Min distance indexes tensor([285., 274., 115., 336., 258.])\n",
      "idx_min_dist: [285 274 115 336 258]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 114\n",
      "Index of smallest elem: 391\n",
      "Index of smallest elem: 393\n",
      "Index of smallest elem: 105\n",
      "Index of smallest elem: 260\n",
      "Min distance indexes tensor([114., 391., 393., 105., 260.])\n",
      "idx_min_dist: [114 391 393 105 260]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 358\n",
      "Index of smallest elem: 436\n",
      "Index of smallest elem: 29\n",
      "Index of smallest elem: 56\n",
      "Min distance indexes tensor([260., 358., 436.,  29.,  56.])\n",
      "idx_min_dist: [260 358 436  29  56]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 56\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 364\n",
      "Index of smallest elem: 25\n",
      "Index of smallest elem: 255\n",
      "Min distance indexes tensor([ 56., 260., 364.,  25., 255.])\n",
      "idx_min_dist: [ 56 260 364  25 255]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 38\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 364\n",
      "Index of smallest elem: 391\n",
      "Index of smallest elem: 213\n",
      "Min distance indexes tensor([ 38., 260., 364., 391., 213.])\n",
      "idx_min_dist: [ 38 260 364 391 213]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 396\n",
      "Index of smallest elem: 365\n",
      "Index of smallest elem: 88\n",
      "Index of smallest elem: 119\n",
      "Index of smallest elem: 358\n",
      "Min distance indexes tensor([396., 365.,  88., 119., 358.])\n",
      "idx_min_dist: [396 365  88 119 358]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 358\n",
      "Index of smallest elem: 326\n",
      "Index of smallest elem: 185\n",
      "Index of smallest elem: 33\n",
      "Index of smallest elem: 299\n",
      "Min distance indexes tensor([358., 326., 185.,  33., 299.])\n",
      "idx_min_dist: [358 326 185  33 299]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 325\n",
      "Index of smallest elem: 171\n",
      "Index of smallest elem: 144\n",
      "Index of smallest elem: 82\n",
      "Index of smallest elem: 311\n",
      "Min distance indexes tensor([325., 171., 144.,  82., 311.])\n",
      "idx_min_dist: [325 171 144  82 311]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 95\n",
      "Index of smallest elem: 266\n",
      "Index of smallest elem: 18\n",
      "Index of smallest elem: 405\n",
      "Index of smallest elem: 220\n",
      "Min distance indexes tensor([ 95., 266.,  18., 405., 220.])\n",
      "idx_min_dist: [ 95 266  18 405 220]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 56\n",
      "Index of smallest elem: 63\n",
      "Index of smallest elem: 179\n",
      "Index of smallest elem: 347\n",
      "Min distance indexes tensor([260.,  56.,  63., 179., 347.])\n",
      "idx_min_dist: [260  56  63 179 347]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 200\n",
      "Index of smallest elem: 396\n",
      "Index of smallest elem: 253\n",
      "Index of smallest elem: 113\n",
      "Index of smallest elem: 25\n",
      "Min distance indexes tensor([200., 396., 253., 113.,  25.])\n",
      "idx_min_dist: [200 396 253 113  25]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 193\n",
      "Index of smallest elem: 41\n",
      "Index of smallest elem: 225\n",
      "Index of smallest elem: 7\n",
      "Index of smallest elem: 391\n",
      "Min distance indexes tensor([193.,  41., 225.,   7., 391.])\n",
      "idx_min_dist: [193  41 225   7 391]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 63\n",
      "Index of smallest elem: 401\n",
      "Index of smallest elem: 140\n",
      "Index of smallest elem: 347\n",
      "Index of smallest elem: 308\n",
      "Min distance indexes tensor([ 63., 401., 140., 347., 308.])\n",
      "idx_min_dist: [ 63 401 140 347 308]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 34\n",
      "Index of smallest elem: 214\n",
      "Index of smallest elem: 295\n",
      "Index of smallest elem: 377\n",
      "Index of smallest elem: 353\n",
      "Min distance indexes tensor([ 34., 214., 295., 377., 353.])\n",
      "idx_min_dist: [ 34 214 295 377 353]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 257\n",
      "Index of smallest elem: 17\n",
      "Index of smallest elem: 82\n",
      "Index of smallest elem: 407\n",
      "Index of smallest elem: 170\n",
      "Min distance indexes tensor([257.,  17.,  82., 407., 170.])\n",
      "idx_min_dist: [257  17  82 407 170]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 29\n",
      "Index of smallest elem: 38\n",
      "Index of smallest elem: 225\n",
      "Index of smallest elem: 391\n",
      "Index of smallest elem: 364\n",
      "Min distance indexes tensor([ 29.,  38., 225., 391., 364.])\n",
      "idx_min_dist: [ 29  38 225 391 364]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 205\n",
      "Index of smallest elem: 10\n",
      "Index of smallest elem: 102\n",
      "Index of smallest elem: 318\n",
      "Index of smallest elem: 45\n",
      "Min distance indexes tensor([205.,  10., 102., 318.,  45.])\n",
      "idx_min_dist: [205  10 102 318  45]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 116\n",
      "Index of smallest elem: 396\n",
      "Index of smallest elem: 373\n",
      "Index of smallest elem: 365\n",
      "Index of smallest elem: 119\n",
      "Min distance indexes tensor([116., 396., 373., 365., 119.])\n",
      "idx_min_dist: [116 396 373 365 119]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 210\n",
      "Index of smallest elem: 281\n",
      "Index of smallest elem: 435\n",
      "Index of smallest elem: 431\n",
      "Index of smallest elem: 204\n",
      "Min distance indexes tensor([210., 281., 435., 431., 204.])\n",
      "idx_min_dist: [210 281 435 431 204]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 222\n",
      "Index of smallest elem: 260\n",
      "Index of smallest elem: 72\n",
      "Index of smallest elem: 29\n",
      "Index of smallest elem: 398\n",
      "Min distance indexes tensor([222., 260.,  72.,  29., 398.])\n",
      "idx_min_dist: [222 260  72  29 398]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 429\n",
      "Index of smallest elem: 338\n",
      "Index of smallest elem: 193\n",
      "Index of smallest elem: 45\n",
      "Index of smallest elem: 225\n",
      "Min distance indexes tensor([429., 338., 193.,  45., 225.])\n",
      "idx_min_dist: [429 338 193  45 225]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 29\n",
      "Index of smallest elem: 87\n",
      "Index of smallest elem: 319\n",
      "Index of smallest elem: 412\n",
      "Index of smallest elem: 419\n",
      "Min distance indexes tensor([ 29.,  87., 319., 412., 419.])\n",
      "idx_min_dist: [ 29  87 319 412 419]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 325\n",
      "Index of smallest elem: 171\n",
      "Index of smallest elem: 25\n",
      "Index of smallest elem: 321\n",
      "Index of smallest elem: 11\n",
      "Min distance indexes tensor([325., 171.,  25., 321.,  11.])\n",
      "idx_min_dist: [325 171  25 321  11]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 149\n",
      "Index of smallest elem: 73\n",
      "Index of smallest elem: 50\n",
      "Index of smallest elem: 335\n",
      "Index of smallest elem: 243\n",
      "Min distance indexes tensor([149.,  73.,  50., 335., 243.])\n",
      "idx_min_dist: [149  73  50 335 243]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 387\n",
      "Index of smallest elem: 394\n",
      "Index of smallest elem: 325\n",
      "Index of smallest elem: 194\n",
      "Index of smallest elem: 106\n",
      "Min distance indexes tensor([387., 394., 325., 194., 106.])\n",
      "idx_min_dist: [387 394 325 194 106]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 134\n",
      "Index of smallest elem: 204\n",
      "Index of smallest elem: 212\n",
      "Index of smallest elem: 52\n",
      "Index of smallest elem: 435\n",
      "Min distance indexes tensor([134., 204., 212.,  52., 435.])\n",
      "idx_min_dist: [134 204 212  52 435]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 92\n",
      "Index of smallest elem: 288\n",
      "Index of smallest elem: 201\n",
      "Index of smallest elem: 355\n",
      "Index of smallest elem: 268\n",
      "Min distance indexes tensor([ 92., 288., 201., 355., 268.])\n",
      "idx_min_dist: [ 92 288 201 355 268]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 390\n",
      "Index of smallest elem: 400\n",
      "Index of smallest elem: 283\n",
      "Index of smallest elem: 75\n",
      "Index of smallest elem: 129\n",
      "Min distance indexes tensor([390., 400., 283.,  75., 129.])\n",
      "idx_min_dist: [390 400 283  75 129]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 62\n",
      "Index of smallest elem: 326\n",
      "Index of smallest elem: 157\n",
      "Index of smallest elem: 10\n",
      "Index of smallest elem: 415\n",
      "Min distance indexes tensor([ 62., 326., 157.,  10., 415.])\n",
      "idx_min_dist: [ 62 326 157  10 415]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 134\n",
      "Index of smallest elem: 133\n",
      "Index of smallest elem: 212\n",
      "Index of smallest elem: 243\n",
      "Index of smallest elem: 281\n",
      "Min distance indexes tensor([134., 133., 212., 243., 281.])\n",
      "idx_min_dist: [134 133 212 243 281]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 114\n",
      "Index of smallest elem: 265\n",
      "Index of smallest elem: 122\n",
      "Index of smallest elem: 393\n",
      "Index of smallest elem: 358\n",
      "Min distance indexes tensor([114., 265., 122., 393., 358.])\n",
      "idx_min_dist: [114 265 122 393 358]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 64\n",
      "Index of smallest elem: 65\n",
      "Index of smallest elem: 313\n",
      "Index of smallest elem: 97\n",
      "Index of smallest elem: 247\n",
      "Min distance indexes tensor([ 64.,  65., 313.,  97., 247.])\n",
      "idx_min_dist: [ 64  65 313  97 247]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 29\n",
      "Index of smallest elem: 239\n",
      "Index of smallest elem: 202\n",
      "Index of smallest elem: 38\n",
      "Index of smallest elem: 326\n",
      "Min distance indexes tensor([ 29., 239., 202.,  38., 326.])\n",
      "idx_min_dist: [ 29 239 202  38 326]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 40\n",
      "Index of smallest elem: 377\n",
      "Index of smallest elem: 79\n",
      "Index of smallest elem: 311\n",
      "Index of smallest elem: 73\n",
      "Min distance indexes tensor([ 40., 377.,  79., 311.,  73.])\n",
      "idx_min_dist: [ 40 377  79 311  73]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 325\n",
      "Index of smallest elem: 394\n",
      "Index of smallest elem: 228\n",
      "Index of smallest elem: 294\n",
      "Index of smallest elem: 344\n",
      "Min distance indexes tensor([325., 394., 228., 294., 344.])\n",
      "idx_min_dist: [325 394 228 294 344]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 33\n",
      "Index of smallest elem: 436\n",
      "Index of smallest elem: 29\n",
      "Index of smallest elem: 0\n",
      "Index of smallest elem: 358\n",
      "Min distance indexes tensor([ 33., 436.,  29.,   0., 358.])\n",
      "idx_min_dist: [ 33 436  29   0 358]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 65\n",
      "Index of smallest elem: 247\n",
      "Index of smallest elem: 127\n",
      "Index of smallest elem: 366\n",
      "Index of smallest elem: 229\n",
      "Min distance indexes tensor([ 65., 247., 127., 366., 229.])\n",
      "idx_min_dist: [ 65 247 127 366 229]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 250\n",
      "Index of smallest elem: 619\n",
      "Index of smallest elem: 378\n",
      "Index of smallest elem: 625\n",
      "Index of smallest elem: 795\n",
      "Min distance indexes tensor([250., 619., 378., 625., 795.])\n",
      "idx_min_dist: [250 619 378 625 795]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 1 0 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 245\n",
      "Index of smallest elem: 187\n",
      "Index of smallest elem: 184\n",
      "Index of smallest elem: 315\n",
      "Index of smallest elem: 33\n",
      "Min distance indexes tensor([245., 187., 184., 315.,  33.])\n",
      "idx_min_dist: [245 187 184 315  33]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 220\n",
      "Index of smallest elem: 405\n",
      "Index of smallest elem: 55\n",
      "Index of smallest elem: 18\n",
      "Index of smallest elem: 306\n",
      "Min distance indexes tensor([220., 405.,  55.,  18., 306.])\n",
      "idx_min_dist: [220 405  55  18 306]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 96\n",
      "Index of smallest elem: 400\n",
      "Index of smallest elem: 200\n",
      "Index of smallest elem: 210\n",
      "Index of smallest elem: 396\n",
      "Min distance indexes tensor([ 96., 400., 200., 210., 396.])\n",
      "idx_min_dist: [ 96 400 200 210 396]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 187\n",
      "Index of smallest elem: 315\n",
      "Index of smallest elem: 255\n",
      "Index of smallest elem: 33\n",
      "Index of smallest elem: 416\n",
      "Min distance indexes tensor([187., 315., 255.,  33., 416.])\n",
      "idx_min_dist: [187 315 255  33 416]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 239\n",
      "Index of smallest elem: 436\n",
      "Index of smallest elem: 398\n",
      "Index of smallest elem: 185\n",
      "Index of smallest elem: 358\n",
      "Min distance indexes tensor([239., 436., 398., 185., 358.])\n",
      "idx_min_dist: [239 436 398 185 358]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 142\n",
      "Index of smallest elem: 380\n",
      "Index of smallest elem: 424\n",
      "Index of smallest elem: 249\n",
      "Index of smallest elem: 396\n",
      "Min distance indexes tensor([142., 380., 424., 249., 396.])\n",
      "idx_min_dist: [142 380 424 249 396]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 325\n",
      "Index of smallest elem: 262\n",
      "Index of smallest elem: 421\n",
      "Index of smallest elem: 61\n",
      "Index of smallest elem: 257\n",
      "Min distance indexes tensor([325., 262., 421.,  61., 257.])\n",
      "idx_min_dist: [325 262 421  61 257]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 115\n",
      "Index of smallest elem: 336\n",
      "Index of smallest elem: 333\n",
      "Index of smallest elem: 354\n",
      "Index of smallest elem: 438\n",
      "Min distance indexes tensor([115., 336., 333., 354., 438.])\n",
      "idx_min_dist: [115 336 333 354 438]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 37\n",
      "Index of smallest elem: 166\n",
      "Index of smallest elem: 70\n",
      "Index of smallest elem: 195\n",
      "Index of smallest elem: 187\n",
      "Min distance indexes tensor([ 37., 166.,  70., 195., 187.])\n",
      "idx_min_dist: [ 37 166  70 195 187]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 122\n",
      "Index of smallest elem: 357\n",
      "Index of smallest elem: 419\n",
      "Index of smallest elem: 12\n",
      "Index of smallest elem: 318\n",
      "Min distance indexes tensor([122., 357., 419.,  12., 318.])\n",
      "idx_min_dist: [122 357 419  12 318]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 144\n",
      "Index of smallest elem: 171\n",
      "Index of smallest elem: 82\n",
      "Index of smallest elem: 46\n",
      "Index of smallest elem: 153\n",
      "Min distance indexes tensor([144., 171.,  82.,  46., 153.])\n",
      "idx_min_dist: [144 171  82  46 153]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 64\n",
      "Index of smallest elem: 46\n",
      "Index of smallest elem: 398\n",
      "Index of smallest elem: 413\n",
      "Index of smallest elem: 6\n",
      "Min distance indexes tensor([ 64.,  46., 398., 413.,   6.])\n",
      "idx_min_dist: [ 64  46 398 413   6]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 435\n",
      "Index of smallest elem: 21\n",
      "Index of smallest elem: 210\n",
      "Index of smallest elem: 333\n",
      "Index of smallest elem: 430\n",
      "Min distance indexes tensor([435.,  21., 210., 333., 430.])\n",
      "idx_min_dist: [435  21 210 333 430]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 152\n",
      "Index of smallest elem: 44\n",
      "Index of smallest elem: 287\n",
      "Index of smallest elem: 119\n",
      "Index of smallest elem: 367\n",
      "Min distance indexes tensor([152.,  44., 287., 119., 367.])\n",
      "idx_min_dist: [152  44 287 119 367]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 393\n",
      "Index of smallest elem: 122\n",
      "Index of smallest elem: 114\n",
      "Index of smallest elem: 252\n",
      "Index of smallest elem: 155\n",
      "Min distance indexes tensor([393., 122., 114., 252., 155.])\n",
      "idx_min_dist: [393 122 114 252 155]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 356\n",
      "Index of smallest elem: 52\n",
      "Index of smallest elem: 212\n",
      "Index of smallest elem: 377\n",
      "Index of smallest elem: 221\n",
      "Min distance indexes tensor([356.,  52., 212., 377., 221.])\n",
      "idx_min_dist: [356  52 212 377 221]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 264\n",
      "Index of smallest elem: 254\n",
      "Index of smallest elem: 83\n",
      "Index of smallest elem: 76\n",
      "Index of smallest elem: 286\n",
      "Min distance indexes tensor([264., 254.,  83.,  76., 286.])\n",
      "idx_min_dist: [264 254  83  76 286]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 64\n",
      "Index of smallest elem: 313\n",
      "Index of smallest elem: 326\n",
      "Index of smallest elem: 239\n",
      "Index of smallest elem: 127\n",
      "Min distance indexes tensor([ 64., 313., 326., 239., 127.])\n",
      "idx_min_dist: [ 64 313 326 239 127]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 119\n",
      "Index of smallest elem: 11\n",
      "Index of smallest elem: 146\n",
      "Index of smallest elem: 300\n",
      "Index of smallest elem: 424\n",
      "Min distance indexes tensor([119.,  11., 146., 300., 424.])\n",
      "idx_min_dist: [119  11 146 300 424]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 220\n",
      "Index of smallest elem: 306\n",
      "Index of smallest elem: 405\n",
      "Index of smallest elem: 151\n",
      "Index of smallest elem: 55\n",
      "Min distance indexes tensor([220., 306., 405., 151.,  55.])\n",
      "idx_min_dist: [220 306 405 151  55]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 66\n",
      "Index of smallest elem: 155\n",
      "Index of smallest elem: 88\n",
      "Index of smallest elem: 245\n",
      "Index of smallest elem: 7\n",
      "Min distance indexes tensor([ 66., 155.,  88., 245.,   7.])\n",
      "idx_min_dist: [ 66 155  88 245   7]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 222\n",
      "Index of smallest elem: 72\n",
      "Index of smallest elem: 46\n",
      "Index of smallest elem: 286\n",
      "Index of smallest elem: 402\n",
      "Min distance indexes tensor([222.,  72.,  46., 286., 402.])\n",
      "idx_min_dist: [222  72  46 286 402]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 117\n",
      "Index of smallest elem: 321\n",
      "Index of smallest elem: 400\n",
      "Index of smallest elem: 270\n",
      "Index of smallest elem: 396\n",
      "Min distance indexes tensor([117., 321., 400., 270., 396.])\n",
      "idx_min_dist: [117 321 400 270 396]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [0 0 0 0 0]\n",
      "Most common label: 0\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 563\n",
      "Index of smallest elem: 844\n",
      "Index of smallest elem: 589\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 567\n",
      "Min distance indexes tensor([563., 844., 589., 695., 567.])\n",
      "idx_min_dist: [563 844 589 695 567]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 473\n",
      "Index of smallest elem: 560\n",
      "Index of smallest elem: 754\n",
      "Index of smallest elem: 615\n",
      "Index of smallest elem: 727\n",
      "Min distance indexes tensor([473., 560., 754., 615., 727.])\n",
      "idx_min_dist: [473 560 754 615 727]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 718\n",
      "Index of smallest elem: 719\n",
      "Index of smallest elem: 545\n",
      "Index of smallest elem: 777\n",
      "Index of smallest elem: 561\n",
      "Min distance indexes tensor([718., 719., 545., 777., 561.])\n",
      "idx_min_dist: [718 719 545 777 561]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 789\n",
      "Index of smallest elem: 500\n",
      "Index of smallest elem: 742\n",
      "Index of smallest elem: 509\n",
      "Index of smallest elem: 855\n",
      "Min distance indexes tensor([789., 500., 742., 509., 855.])\n",
      "idx_min_dist: [789 500 742 509 855]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 777\n",
      "Index of smallest elem: 561\n",
      "Index of smallest elem: 477\n",
      "Index of smallest elem: 718\n",
      "Index of smallest elem: 524\n",
      "Min distance indexes tensor([777., 561., 477., 718., 524.])\n",
      "idx_min_dist: [777 561 477 718 524]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 540\n",
      "Index of smallest elem: 873\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 638\n",
      "Index of smallest elem: 775\n",
      "Min distance indexes tensor([540., 873., 672., 638., 775.])\n",
      "idx_min_dist: [540 873 672 638 775]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 805\n",
      "Index of smallest elem: 726\n",
      "Index of smallest elem: 649\n",
      "Index of smallest elem: 812\n",
      "Index of smallest elem: 646\n",
      "Min distance indexes tensor([805., 726., 649., 812., 646.])\n",
      "idx_min_dist: [805 726 649 812 646]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 530\n",
      "Index of smallest elem: 735\n",
      "Index of smallest elem: 720\n",
      "Index of smallest elem: 800\n",
      "Index of smallest elem: 613\n",
      "Min distance indexes tensor([530., 735., 720., 800., 613.])\n",
      "idx_min_dist: [530 735 720 800 613]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 684\n",
      "Index of smallest elem: 501\n",
      "Index of smallest elem: 659\n",
      "Index of smallest elem: 516\n",
      "Index of smallest elem: 477\n",
      "Min distance indexes tensor([684., 501., 659., 516., 477.])\n",
      "idx_min_dist: [684 501 659 516 477]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 573\n",
      "Index of smallest elem: 716\n",
      "Index of smallest elem: 478\n",
      "Index of smallest elem: 712\n",
      "Index of smallest elem: 446\n",
      "Min distance indexes tensor([573., 716., 478., 712., 446.])\n",
      "idx_min_dist: [573 716 478 712 446]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 655\n",
      "Index of smallest elem: 846\n",
      "Index of smallest elem: 561\n",
      "Index of smallest elem: 684\n",
      "Index of smallest elem: 508\n",
      "Min distance indexes tensor([655., 846., 561., 684., 508.])\n",
      "idx_min_dist: [655 846 561 684 508]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 749\n",
      "Index of smallest elem: 476\n",
      "Index of smallest elem: 269\n",
      "Index of smallest elem: 315\n",
      "Index of smallest elem: 796\n",
      "Min distance indexes tensor([749., 476., 269., 315., 796.])\n",
      "idx_min_dist: [749 476 269 315 796]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 0 0 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 591\n",
      "Index of smallest elem: 501\n",
      "Index of smallest elem: 684\n",
      "Index of smallest elem: 475\n",
      "Index of smallest elem: 869\n",
      "Min distance indexes tensor([591., 501., 684., 475., 869.])\n",
      "idx_min_dist: [591 501 684 475 869]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 842\n",
      "Index of smallest elem: 643\n",
      "Index of smallest elem: 460\n",
      "Index of smallest elem: 717\n",
      "Index of smallest elem: 442\n",
      "Min distance indexes tensor([842., 643., 460., 717., 442.])\n",
      "idx_min_dist: [842 643 460 717 442]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 664\n",
      "Index of smallest elem: 492\n",
      "Index of smallest elem: 774\n",
      "Index of smallest elem: 559\n",
      "Index of smallest elem: 776\n",
      "Min distance indexes tensor([664., 492., 774., 559., 776.])\n",
      "idx_min_dist: [664 492 774 559 776]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 573\n",
      "Index of smallest elem: 782\n",
      "Index of smallest elem: 804\n",
      "Index of smallest elem: 614\n",
      "Index of smallest elem: 530\n",
      "Min distance indexes tensor([573., 782., 804., 614., 530.])\n",
      "idx_min_dist: [573 782 804 614 530]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 512\n",
      "Index of smallest elem: 779\n",
      "Index of smallest elem: 597\n",
      "Index of smallest elem: 506\n",
      "Index of smallest elem: 673\n",
      "Min distance indexes tensor([512., 779., 597., 506., 673.])\n",
      "idx_min_dist: [512 779 597 506 673]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 622\n",
      "Index of smallest elem: 498\n",
      "Index of smallest elem: 579\n",
      "Index of smallest elem: 597\n",
      "Index of smallest elem: 485\n",
      "Min distance indexes tensor([622., 498., 579., 597., 485.])\n",
      "idx_min_dist: [622 498 579 597 485]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 619\n",
      "Index of smallest elem: 796\n",
      "Index of smallest elem: 851\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 598\n",
      "Min distance indexes tensor([619., 796., 851., 695., 598.])\n",
      "idx_min_dist: [619 796 851 695 598]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 489\n",
      "Index of smallest elem: 576\n",
      "Index of smallest elem: 606\n",
      "Index of smallest elem: 648\n",
      "Index of smallest elem: 656\n",
      "Min distance indexes tensor([489., 576., 606., 648., 656.])\n",
      "idx_min_dist: [489 576 606 648 656]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 443\n",
      "Index of smallest elem: 552\n",
      "Index of smallest elem: 722\n",
      "Index of smallest elem: 867\n",
      "Index of smallest elem: 575\n",
      "Min distance indexes tensor([443., 552., 722., 867., 575.])\n",
      "idx_min_dist: [443 552 722 867 575]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 727\n",
      "Index of smallest elem: 741\n",
      "Index of smallest elem: 707\n",
      "Index of smallest elem: 455\n",
      "Index of smallest elem: 656\n",
      "Min distance indexes tensor([727., 741., 707., 455., 656.])\n",
      "idx_min_dist: [727 741 707 455 656]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 603\n",
      "Index of smallest elem: 444\n",
      "Index of smallest elem: 536\n",
      "Index of smallest elem: 607\n",
      "Index of smallest elem: 453\n",
      "Min distance indexes tensor([603., 444., 536., 607., 453.])\n",
      "idx_min_dist: [603 444 536 607 453]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 619\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 762\n",
      "Index of smallest elem: 567\n",
      "Min distance indexes tensor([619., 672., 695., 762., 567.])\n",
      "idx_min_dist: [619 672 695 762 567]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 612\n",
      "Index of smallest elem: 718\n",
      "Index of smallest elem: 795\n",
      "Index of smallest elem: 477\n",
      "Index of smallest elem: 619\n",
      "Min distance indexes tensor([612., 718., 795., 477., 619.])\n",
      "idx_min_dist: [612 718 795 477 619]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 480\n",
      "Index of smallest elem: 849\n",
      "Index of smallest elem: 587\n",
      "Index of smallest elem: 741\n",
      "Index of smallest elem: 797\n",
      "Min distance indexes tensor([480., 849., 587., 741., 797.])\n",
      "idx_min_dist: [480 849 587 741 797]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 646\n",
      "Index of smallest elem: 726\n",
      "Index of smallest elem: 724\n",
      "Index of smallest elem: 805\n",
      "Index of smallest elem: 812\n",
      "Min distance indexes tensor([646., 726., 724., 805., 812.])\n",
      "idx_min_dist: [646 726 724 805 812]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 851\n",
      "Index of smallest elem: 719\n",
      "Index of smallest elem: 465\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 695\n",
      "Min distance indexes tensor([851., 719., 465., 672., 695.])\n",
      "idx_min_dist: [851 719 465 672 695]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 730\n",
      "Index of smallest elem: 506\n",
      "Index of smallest elem: 780\n",
      "Index of smallest elem: 622\n",
      "Index of smallest elem: 673\n",
      "Min distance indexes tensor([730., 506., 780., 622., 673.])\n",
      "idx_min_dist: [730 506 780 622 673]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 576\n",
      "Index of smallest elem: 606\n",
      "Index of smallest elem: 489\n",
      "Index of smallest elem: 648\n",
      "Index of smallest elem: 452\n",
      "Min distance indexes tensor([576., 606., 489., 648., 452.])\n",
      "idx_min_dist: [576 606 489 648 452]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 516\n",
      "Index of smallest elem: 475\n",
      "Index of smallest elem: 684\n",
      "Index of smallest elem: 469\n",
      "Index of smallest elem: 591\n",
      "Min distance indexes tensor([516., 475., 684., 469., 591.])\n",
      "idx_min_dist: [516 475 684 469 591]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 873\n",
      "Index of smallest elem: 522\n",
      "Index of smallest elem: 540\n",
      "Index of smallest elem: 834\n",
      "Index of smallest elem: 860\n",
      "Min distance indexes tensor([873., 522., 540., 834., 860.])\n",
      "idx_min_dist: [873 522 540 834 860]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 805\n",
      "Index of smallest elem: 726\n",
      "Index of smallest elem: 646\n",
      "Index of smallest elem: 543\n",
      "Index of smallest elem: 725\n",
      "Min distance indexes tensor([805., 726., 646., 543., 725.])\n",
      "idx_min_dist: [805 726 646 543 725]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 470\n",
      "Index of smallest elem: 512\n",
      "Index of smallest elem: 851\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 538\n",
      "Min distance indexes tensor([470., 512., 851., 672., 538.])\n",
      "idx_min_dist: [470 512 851 672 538]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 793\n",
      "Index of smallest elem: 732\n",
      "Index of smallest elem: 871\n",
      "Index of smallest elem: 803\n",
      "Index of smallest elem: 706\n",
      "Min distance indexes tensor([793., 732., 871., 803., 706.])\n",
      "idx_min_dist: [793 732 871 803 706]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 508\n",
      "Index of smallest elem: 515\n",
      "Index of smallest elem: 655\n",
      "Index of smallest elem: 876\n",
      "Index of smallest elem: 841\n",
      "Min distance indexes tensor([508., 515., 655., 876., 841.])\n",
      "idx_min_dist: [508 515 655 876 841]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 555\n",
      "Index of smallest elem: 558\n",
      "Index of smallest elem: 525\n",
      "Index of smallest elem: 592\n",
      "Index of smallest elem: 543\n",
      "Min distance indexes tensor([555., 558., 525., 592., 543.])\n",
      "idx_min_dist: [555 558 525 592 543]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 662\n",
      "Index of smallest elem: 811\n",
      "Index of smallest elem: 482\n",
      "Index of smallest elem: 783\n",
      "Index of smallest elem: 458\n",
      "Min distance indexes tensor([662., 811., 482., 783., 458.])\n",
      "idx_min_dist: [662 811 482 783 458]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 496\n",
      "Index of smallest elem: 570\n",
      "Index of smallest elem: 488\n",
      "Index of smallest elem: 475\n",
      "Index of smallest elem: 513\n",
      "Min distance indexes tensor([496., 570., 488., 475., 513.])\n",
      "idx_min_dist: [496 570 488 475 513]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 870\n",
      "Index of smallest elem: 524\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 782\n",
      "Min distance indexes tensor([870., 524., 695., 672., 782.])\n",
      "idx_min_dist: [870 524 695 672 782]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 865\n",
      "Index of smallest elem: 647\n",
      "Index of smallest elem: 542\n",
      "Index of smallest elem: 661\n",
      "Index of smallest elem: 792\n",
      "Min distance indexes tensor([865., 647., 542., 661., 792.])\n",
      "idx_min_dist: [865 647 542 661 792]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 497\n",
      "Index of smallest elem: 482\n",
      "Index of smallest elem: 458\n",
      "Index of smallest elem: 662\n",
      "Index of smallest elem: 621\n",
      "Min distance indexes tensor([497., 482., 458., 662., 621.])\n",
      "idx_min_dist: [497 482 458 662 621]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 846\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 876\n",
      "Index of smallest elem: 507\n",
      "Index of smallest elem: 672\n",
      "Min distance indexes tensor([846., 695., 876., 507., 672.])\n",
      "idx_min_dist: [846 695 876 507 672]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 578\n",
      "Index of smallest elem: 731\n",
      "Index of smallest elem: 555\n",
      "Index of smallest elem: 543\n",
      "Index of smallest elem: 706\n",
      "Min distance indexes tensor([578., 731., 555., 543., 706.])\n",
      "idx_min_dist: [578 731 555 543 706]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 869\n",
      "Index of smallest elem: 676\n",
      "Index of smallest elem: 513\n",
      "Index of smallest elem: 469\n",
      "Index of smallest elem: 501\n",
      "Min distance indexes tensor([869., 676., 513., 469., 501.])\n",
      "idx_min_dist: [869 676 513 469 501]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 596\n",
      "Index of smallest elem: 866\n",
      "Index of smallest elem: 637\n",
      "Index of smallest elem: 825\n",
      "Index of smallest elem: 505\n",
      "Min distance indexes tensor([596., 866., 637., 825., 505.])\n",
      "idx_min_dist: [596 866 637 825 505]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 870\n",
      "Index of smallest elem: 834\n",
      "Index of smallest elem: 619\n",
      "Index of smallest elem: 777\n",
      "Index of smallest elem: 477\n",
      "Min distance indexes tensor([870., 834., 619., 777., 477.])\n",
      "idx_min_dist: [870 834 619 777 477]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 543\n",
      "Index of smallest elem: 525\n",
      "Index of smallest elem: 565\n",
      "Index of smallest elem: 558\n",
      "Index of smallest elem: 703\n",
      "Min distance indexes tensor([543., 525., 565., 558., 703.])\n",
      "idx_min_dist: [543 525 565 558 703]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 725\n",
      "Index of smallest elem: 517\n",
      "Index of smallest elem: 548\n",
      "Index of smallest elem: 547\n",
      "Index of smallest elem: 590\n",
      "Min distance indexes tensor([725., 517., 548., 547., 590.])\n",
      "idx_min_dist: [725 517 548 547 590]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 741\n",
      "Index of smallest elem: 650\n",
      "Index of smallest elem: 572\n",
      "Index of smallest elem: 587\n",
      "Index of smallest elem: 656\n",
      "Min distance indexes tensor([741., 650., 572., 587., 656.])\n",
      "idx_min_dist: [741 650 572 587 656]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 478\n",
      "Index of smallest elem: 538\n",
      "Index of smallest elem: 462\n",
      "Index of smallest elem: 468\n",
      "Index of smallest elem: 712\n",
      "Min distance indexes tensor([478., 538., 462., 468., 712.])\n",
      "idx_min_dist: [478 538 462 468 712]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 707\n",
      "Index of smallest elem: 576\n",
      "Index of smallest elem: 584\n",
      "Index of smallest elem: 656\n",
      "Index of smallest elem: 480\n",
      "Min distance indexes tensor([707., 576., 584., 656., 480.])\n",
      "idx_min_dist: [707 576 584 656 480]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 678\n",
      "Index of smallest elem: 609\n",
      "Index of smallest elem: 614\n",
      "Index of smallest elem: 538\n",
      "Index of smallest elem: 599\n",
      "Min distance indexes tensor([678., 609., 614., 538., 599.])\n",
      "idx_min_dist: [678 609 614 538 599]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 641\n",
      "Index of smallest elem: 444\n",
      "Index of smallest elem: 514\n",
      "Index of smallest elem: 841\n",
      "Index of smallest elem: 567\n",
      "Min distance indexes tensor([641., 444., 514., 841., 567.])\n",
      "idx_min_dist: [641 444 514 841 567]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 861\n",
      "Index of smallest elem: 464\n",
      "Index of smallest elem: 643\n",
      "Index of smallest elem: 693\n",
      "Index of smallest elem: 799\n",
      "Min distance indexes tensor([861., 464., 643., 693., 799.])\n",
      "idx_min_dist: [861 464 643 693 799]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 652\n",
      "Index of smallest elem: 605\n",
      "Index of smallest elem: 876\n",
      "Index of smallest elem: 569\n",
      "Index of smallest elem: 868\n",
      "Min distance indexes tensor([652., 605., 876., 569., 868.])\n",
      "idx_min_dist: [652 605 876 569 868]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 691\n",
      "Index of smallest elem: 709\n",
      "Index of smallest elem: 559\n",
      "Index of smallest elem: 877\n",
      "Index of smallest elem: 815\n",
      "Min distance indexes tensor([691., 709., 559., 877., 815.])\n",
      "idx_min_dist: [691 709 559 877 815]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 837\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 652\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 864\n",
      "Min distance indexes tensor([837., 672., 652., 695., 864.])\n",
      "idx_min_dist: [837 672 652 695 864]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 581\n",
      "Index of smallest elem: 480\n",
      "Index of smallest elem: 656\n",
      "Index of smallest elem: 529\n",
      "Index of smallest elem: 843\n",
      "Min distance indexes tensor([581., 480., 656., 529., 843.])\n",
      "idx_min_dist: [581 480 656 529 843]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 837\n",
      "Index of smallest elem: 522\n",
      "Index of smallest elem: 477\n",
      "Index of smallest elem: 777\n",
      "Index of smallest elem: 860\n",
      "Min distance indexes tensor([837., 522., 477., 777., 860.])\n",
      "idx_min_dist: [837 522 477 777 860]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 780\n",
      "Index of smallest elem: 597\n",
      "Index of smallest elem: 622\n",
      "Index of smallest elem: 506\n",
      "Index of smallest elem: 474\n",
      "Min distance indexes tensor([780., 597., 622., 506., 474.])\n",
      "idx_min_dist: [780 597 622 506 474]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 622\n",
      "Index of smallest elem: 506\n",
      "Index of smallest elem: 705\n",
      "Index of smallest elem: 755\n",
      "Index of smallest elem: 579\n",
      "Min distance indexes tensor([622., 506., 705., 755., 579.])\n",
      "idx_min_dist: [622 506 705 755 579]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 716\n",
      "Index of smallest elem: 775\n",
      "Index of smallest elem: 712\n",
      "Index of smallest elem: 614\n",
      "Index of smallest elem: 804\n",
      "Min distance indexes tensor([716., 775., 712., 614., 804.])\n",
      "idx_min_dist: [716 775 712 614 804]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 805\n",
      "Index of smallest elem: 726\n",
      "Index of smallest elem: 543\n",
      "Index of smallest elem: 706\n",
      "Index of smallest elem: 646\n",
      "Min distance indexes tensor([805., 726., 543., 706., 646.])\n",
      "idx_min_dist: [805 726 543 706 646]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 726\n",
      "Index of smallest elem: 805\n",
      "Index of smallest elem: 646\n",
      "Index of smallest elem: 543\n",
      "Index of smallest elem: 725\n",
      "Min distance indexes tensor([726., 805., 646., 543., 725.])\n",
      "idx_min_dist: [726 805 646 543 725]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 587\n",
      "Index of smallest elem: 843\n",
      "Index of smallest elem: 455\n",
      "Index of smallest elem: 459\n",
      "Index of smallest elem: 480\n",
      "Min distance indexes tensor([587., 843., 455., 459., 480.])\n",
      "idx_min_dist: [587 843 455 459 480]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 652\n",
      "Index of smallest elem: 777\n",
      "Index of smallest elem: 864\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 837\n",
      "Min distance indexes tensor([652., 777., 864., 695., 837.])\n",
      "idx_min_dist: [652 777 864 695 837]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 479\n",
      "Index of smallest elem: 827\n",
      "Index of smallest elem: 590\n",
      "Index of smallest elem: 517\n",
      "Index of smallest elem: 781\n",
      "Min distance indexes tensor([479., 827., 590., 517., 781.])\n",
      "idx_min_dist: [479 827 590 517 781]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 870\n",
      "Index of smallest elem: 477\n",
      "Index of smallest elem: 540\n",
      "Index of smallest elem: 478\n",
      "Min distance indexes tensor([672., 870., 477., 540., 478.])\n",
      "idx_min_dist: [672 870 477 540 478]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 648\n",
      "Index of smallest elem: 489\n",
      "Index of smallest elem: 606\n",
      "Index of smallest elem: 576\n",
      "Index of smallest elem: 624\n",
      "Min distance indexes tensor([648., 489., 606., 576., 624.])\n",
      "idx_min_dist: [648 489 606 576 624]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 834\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 563\n",
      "Index of smallest elem: 870\n",
      "Min distance indexes tensor([695., 834., 672., 563., 870.])\n",
      "idx_min_dist: [695 834 672 563 870]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 498\n",
      "Index of smallest elem: 506\n",
      "Index of smallest elem: 620\n",
      "Index of smallest elem: 597\n",
      "Index of smallest elem: 579\n",
      "Min distance indexes tensor([498., 506., 620., 597., 579.])\n",
      "idx_min_dist: [498 506 620 597 579]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 827\n",
      "Index of smallest elem: 590\n",
      "Index of smallest elem: 725\n",
      "Index of smallest elem: 832\n",
      "Index of smallest elem: 548\n",
      "Min distance indexes tensor([827., 590., 725., 832., 548.])\n",
      "idx_min_dist: [827 590 725 832 548]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 652\n",
      "Index of smallest elem: 537\n",
      "Index of smallest elem: 766\n",
      "Index of smallest elem: 775\n",
      "Index of smallest elem: 876\n",
      "Min distance indexes tensor([652., 537., 766., 775., 876.])\n",
      "idx_min_dist: [652 537 766 775 876]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 551\n",
      "Index of smallest elem: 453\n",
      "Index of smallest elem: 607\n",
      "Index of smallest elem: 810\n",
      "Index of smallest elem: 680\n",
      "Min distance indexes tensor([551., 453., 607., 810., 680.])\n",
      "idx_min_dist: [551 453 607 810 680]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 595\n",
      "Index of smallest elem: 523\n",
      "Index of smallest elem: 744\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 695\n",
      "Min distance indexes tensor([595., 523., 744., 672., 695.])\n",
      "idx_min_dist: [595 523 744 672 695]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 743\n",
      "Index of smallest elem: 707\n",
      "Index of smallest elem: 581\n",
      "Index of smallest elem: 843\n",
      "Index of smallest elem: 481\n",
      "Min distance indexes tensor([743., 707., 581., 843., 481.])\n",
      "idx_min_dist: [743 707 581 843 481]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 681\n",
      "Index of smallest elem: 695\n",
      "Index of smallest elem: 463\n",
      "Index of smallest elem: 834\n",
      "Index of smallest elem: 600\n",
      "Min distance indexes tensor([681., 695., 463., 834., 600.])\n",
      "idx_min_dist: [681 695 463 834 600]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 643\n",
      "Index of smallest elem: 725\n",
      "Index of smallest elem: 717\n",
      "Index of smallest elem: 861\n",
      "Index of smallest elem: 847\n",
      "Min distance indexes tensor([643., 725., 717., 861., 847.])\n",
      "idx_min_dist: [643 725 717 861 847]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 522\n",
      "Index of smallest elem: 589\n",
      "Index of smallest elem: 562\n",
      "Index of smallest elem: 598\n",
      "Index of smallest elem: 860\n",
      "Min distance indexes tensor([522., 589., 562., 598., 860.])\n",
      "idx_min_dist: [522 589 562 598 860]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 801\n",
      "Index of smallest elem: 598\n",
      "Index of smallest elem: 542\n",
      "Index of smallest elem: 768\n",
      "Index of smallest elem: 537\n",
      "Min distance indexes tensor([801., 598., 542., 768., 537.])\n",
      "idx_min_dist: [801 598 542 768 537]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 845\n",
      "Index of smallest elem: 487\n",
      "Index of smallest elem: 788\n",
      "Index of smallest elem: 552\n",
      "Index of smallest elem: 840\n",
      "Min distance indexes tensor([845., 487., 788., 552., 840.])\n",
      "idx_min_dist: [845 487 788 552 840]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 672\n",
      "Index of smallest elem: 834\n",
      "Index of smallest elem: 763\n",
      "Index of smallest elem: 526\n",
      "Index of smallest elem: 466\n",
      "Min distance indexes tensor([672., 834., 763., 526., 466.])\n",
      "idx_min_dist: [672 834 763 526 466]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 774\n",
      "Index of smallest elem: 627\n",
      "Index of smallest elem: 664\n",
      "Index of smallest elem: 559\n",
      "Index of smallest elem: 750\n",
      "Min distance indexes tensor([774., 627., 664., 559., 750.])\n",
      "idx_min_dist: [774 627 664 559 750]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 583\n",
      "Index of smallest elem: 740\n",
      "Index of smallest elem: 769\n",
      "Index of smallest elem: 671\n",
      "Index of smallest elem: 494\n",
      "Min distance indexes tensor([583., 740., 769., 671., 494.])\n",
      "idx_min_dist: [583 740 769 671 494]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 494\n",
      "Index of smallest elem: 769\n",
      "Index of smallest elem: 851\n",
      "Index of smallest elem: 808\n",
      "Index of smallest elem: 671\n",
      "Min distance indexes tensor([494., 769., 851., 808., 671.])\n",
      "idx_min_dist: [494 769 851 808 671]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 646\n",
      "Index of smallest elem: 726\n",
      "Index of smallest elem: 805\n",
      "Index of smallest elem: 706\n",
      "Index of smallest elem: 543\n",
      "Min distance indexes tensor([646., 726., 805., 706., 543.])\n",
      "idx_min_dist: [646 726 805 706 543]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 731\n",
      "Index of smallest elem: 500\n",
      "Index of smallest elem: 578\n",
      "Index of smallest elem: 742\n",
      "Index of smallest elem: 555\n",
      "Min distance indexes tensor([731., 500., 578., 742., 555.])\n",
      "idx_min_dist: [731 500 578 742 555]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 529\n",
      "Index of smallest elem: 791\n",
      "Index of smallest elem: 624\n",
      "Index of smallest elem: 723\n",
      "Index of smallest elem: 455\n",
      "Min distance indexes tensor([529., 791., 624., 723., 455.])\n",
      "idx_min_dist: [529 791 624 723 455]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 509\n",
      "Index of smallest elem: 500\n",
      "Index of smallest elem: 789\n",
      "Index of smallest elem: 473\n",
      "Index of smallest elem: 742\n",
      "Min distance indexes tensor([509., 500., 789., 473., 742.])\n",
      "idx_min_dist: [509 500 789 473 742]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 482\n",
      "Index of smallest elem: 662\n",
      "Index of smallest elem: 621\n",
      "Index of smallest elem: 783\n",
      "Index of smallest elem: 604\n",
      "Min distance indexes tensor([482., 662., 621., 783., 604.])\n",
      "idx_min_dist: [482 662 621 783 604]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 753\n",
      "Index of smallest elem: 667\n",
      "Index of smallest elem: 756\n",
      "Index of smallest elem: 483\n",
      "Index of smallest elem: 724\n",
      "Min distance indexes tensor([753., 667., 756., 483., 724.])\n",
      "idx_min_dist: [753 667 756 483 724]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n",
      "Indexes size: torch.Size([5])\n",
      "Shape of distances: torch.Size([878])\n",
      "Index of smallest elem: 480\n",
      "Index of smallest elem: 587\n",
      "Index of smallest elem: 707\n",
      "Index of smallest elem: 459\n",
      "Index of smallest elem: 743\n",
      "Min distance indexes tensor([480., 587., 707., 459., 743.])\n",
      "idx_min_dist: [480 587 707 459 743]\n",
      "Shape of near labels: (5,) should be K\n",
      "Near labels: [1 1 1 1 1]\n",
      "Most common label: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn(train_features, train_labels, test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2 (2 points)** Perform OoD detection on the test features (```test_features_w_ood```) using a k-NN distance based OoD-ness score. Find a threshold on your OoD-ness score such that 95% of the OoD examples are filtered out. How much TUMOR and STROMA have also been filtered out? Finally, assign prediction -1 to filter out examples and compute the average class-wise accuracy of your prediction with test labels (```test_labels_w_ood```).\n",
    "\n",
    "*Note:* The OoD-ness is based on the distance to the k-nearest neighbors. The formulation is up to you. You have to justify your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2\n",
    "### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3 (1 point)** Is k-NN better than Mahalanobis distance ? Make an hypothesis for the reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4 (1 point)** Do you think we can suggest the approach presented in this exercise to compute TUMOR/STROMA ratio automatically ? Justify your thoughs. If not, suggest at least two ideas to improve it.\n",
    "\n",
    "*Note:* Annotating all the training dataset is not an option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 (12 points)\n",
    "In this part, we aim to classify cervical cells resulting from Pap smear tests. To that end we'll be using a publicly available cell dataset: Sipakmed (https://www.cs.uoi.gr/~marina/sipakmed.html). The dataset is composed of 4049 images of isolated cells cropped from 966 cluster cell images of Pap smear slides. Each cell in the dataset has been categorized in either of the following categories: \n",
    "\n",
    "    - Superficial-Intermediate.\n",
    "    - Parabasal.\n",
    "    - Koilocytotic.\n",
    "    - Dysketarotic.\n",
    "    - Metaplastic.\n",
    "Your objective is to implement a classifier to automate the cell classification process. To ease your work we provide you with pre-computed embeddings for each images (`lab-03-data/part2/sipakmed_clean_embeddings.pth`). The embeddings are obtained from a pre-trained ResNet-50 (https://arxiv.org/pdf/1512.03385.pdf) and the corresponding images are also provided (`lab-03-data/part2/sipakmed_clean`). Note that you are free to discard the provided embeddings and work directy with the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dataset (4 points)\n",
    "Your first task is prepare the dataset such that it can be used to train your model. For that purpose we prepared the skeleton of the class `Sipakmed` that inherits from the class `Dataset` of PyTorch. Read the documentation (https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) and complete the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features\n",
    "features_path = '../data/lab-03-data2023/part2/sipakmed_clean_embeddings.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sipakmed(Dataset):\n",
    "    phase_dict = {\n",
    "            'train': {'start': 0.0, 'stop': 0.5},\n",
    "            'val': {'start': 0.5, 'stop': 0.75},\n",
    "            'test': {'start': 0.75, 'stop': 1.0}\n",
    "    }\n",
    "    label_dict = {\n",
    "        'im_Superficial-Intermediate': 0,\n",
    "        'im_Parabasal': 1, \n",
    "        'im_Metaplastic': 2,\n",
    "        'im_Koilocytotic': 3,\n",
    "        'im_Dyskeratotic': 4\n",
    "    }\n",
    "    \n",
    "    def __init__(self, features_path, phase):\n",
    "\n",
    "        super(Sipakmed, self).__init__()\n",
    "        # Store class attributes\n",
    "        self.phase = phase\n",
    "        \n",
    "        # Collect the dataimport torch\n",
    "        import torch.nn.functional as F\n",
    "        import numpy as np\n",
    "        self.raw_data = torch.load(features_path)\n",
    "        self.features, self.labels, self.paths = self.collect_data()\n",
    "        \n",
    "    def collect_data(self):\n",
    "        # Iterate over the dirs/classes\n",
    "        features, labels, paths = [], [], []\n",
    "        for dir_name, dir_dict in self.raw_data.items():\n",
    "            # Get the paths and embeddings\n",
    "            dir_paths, dir_embeddings = list(zip(*[(k, v) for k, v in dir_dict.items()]))\n",
    "            \n",
    "            # Split\n",
    "            n = len(dir_paths)\n",
    "            np.random.seed(42)\n",
    "            permutations = np.random.permutation(n)\n",
    "            dir_paths = np.array(dir_paths)[permutations]\n",
    "            dir_embeddings = torch.stack(dir_embeddings)[permutations]\n",
    "            n_start = int(n * self.phase_dict[self.phase]['start'])\n",
    "            n_stop = int(n * self.phase_dict[self.phase]['stop'])\n",
    "            dir_embeddings = dir_embeddings[n_start: n_stop]\n",
    "            dir_paths = dir_paths[n_start: n_stop]\n",
    "    \n",
    "            # Store\n",
    "            features.append(dir_embeddings)\n",
    "            paths.append(dir_paths)\n",
    "            dir_labels = torch.tensor([self.label_dict[p.split('/')[-2]] for p in dir_paths])\n",
    "            labels.append(dir_labels)\n",
    "            \n",
    "        # Merge\n",
    "        features = torch.cat(features)\n",
    "        labels = torch.cat(labels)\n",
    "        paths = np.concatenate(paths)\n",
    "        return features, labels, paths\n",
    "            \n",
    "        \n",
    "    def __len__(self,):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns the embedding, label, and image path of queried index.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE\n",
    "        return embedding, label, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the implementation of `Sipakmed` completed, create 3 instances of the class (train/val/test) with the corresponding `phase` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the datasets\n",
    "train_dataset = ### YOUR CODE\n",
    "val_dataset = ### YOUR CODE\n",
    "test_dataset = ### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your datasets are ready, use the class `DataLoader` from PyTorch to let it handle efficiently the batching, shuffling, etc. of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the data loaders\n",
    "train_loader = ### YOUR CODE\n",
    "val_loader = ### YOUR CODE\n",
    "test_loader = ### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get to know your data. Plot a few example images for each class of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training example\n",
    "### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training (4 points)\n",
    "In this part your objective is to implement the required tools to train your model. The first thing you'll need is a a model which takes as input the pre-computed features and returns the corresponding class probabilities/logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the model\n",
    "embedding_dim = train_dataset.features.shape[1]\n",
    "model = ### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer will keep track of your model's parameters, gradients, etc (https://pytorch.org/docs/stable/optim.html). It is responsible to update your model's parameters after each forward pass using the backpropagation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizer\n",
    "optimizer = ### YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the loss\n",
    "criterion = ### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function that takes as input the model's output and the corresponding labels and returns the perÃ§entage of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of predictions based on the model outputs (NxK: N samples, K classes) \n",
    "    and the labels (N: N samples).\n",
    "    \"\"\"\n",
    "    ### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a funtion `train` that forwards the complete training set through your model (= 1 epoch) and updates its parameters after each forward pass. To keep track of the training process make sure to at least return the accuracy of the model and the average loss it incurred through the current epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, loader):\n",
    "    # Set the model in train mode\n",
    "    ### YOUR CODE\n",
    "    \n",
    "    # Iterate over the batches\n",
    "    full_outputs = []\n",
    "    full_labels = []\n",
    "    losses = []\n",
    "    for batch in loader:\n",
    "        # Get the embeddings, labels and paths \n",
    "        ### YOUR CODE\n",
    "        \n",
    "        # Feed the embeddings to the model\n",
    "        ### YOUR CODE\n",
    "\n",
    "        # Compute cross entropy loss\n",
    "        ### YOUR CODE\n",
    "        \n",
    "        # Reset the gradients\n",
    "        ### YOUR CODE\n",
    "        \n",
    "        # Backpropagate\n",
    "        ### YOUR CODE\n",
    "\n",
    "        # Update the parameters\n",
    "        ### YOUR CODE\n",
    "        \n",
    "        # Store the outputs, labels and loss\n",
    "        ### YOUR CODE\n",
    "    \n",
    "    # Concat\n",
    "    full_outputs = torch.cat(full_outputs).cpu()\n",
    "    full_labels = torch.cat(full_labels).cpu()\n",
    "    losses = torch.stack(losses).mean().cpu()\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    ### YOUR CODE\n",
    "    return acc, full_outputs, full_labels, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a funtion `validate` that forwards the complete validation or test set through your model and evaluates its predictions. To keep track of the training process make sure to at least return the accuracy of the model and the average loss it incurred through the current epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(model, criterion, loader):\n",
    "    # Set the model in train mode\n",
    "    ### YOUR CODE\n",
    "    \n",
    "    # Iterate over the batches\n",
    "    full_outputs = []\n",
    "    full_labels = []\n",
    "    full_paths = []\n",
    "    losses = []\n",
    "    for batch in loader:\n",
    "        # Get the embeddings, labels and paths\n",
    "        ### YOUR CODE\n",
    "        \n",
    "        # Feed the embeddings to the model\n",
    "        ### YOUR CODE\n",
    "\n",
    "        # Compute cross entropy loss\n",
    "        l### YOUR CODE\n",
    "        \n",
    "        # Store the outputs, labels and loss\n",
    "        ### YOUR CODE\n",
    "    \n",
    "    # Concat\n",
    "    full_outputs = torch.cat(full_outputs).cpu()\n",
    "    full_labels = torch.cat(full_labels).cpu()\n",
    "    losses = torch.stack(losses).mean().cpu()\n",
    "    full_paths = np.concatenate(full_paths)\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    ### YOUR CODE\n",
    "    return acc, full_outputs, full_labels, losses, full_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to train you model. Alternate between training and validation steps to find and save the best model (best accuracy on the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "epochs = ### YOUR CODE\n",
    "best_acc = ### YOUR CODE\n",
    "model_savepath = '../data'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    ### YOUR CODE\n",
    "\n",
    "    # Evaluate\n",
    "    ### YOUR CODE\n",
    "    \n",
    "    # Save the model\n",
    "    if val_acc > best_acc:\n",
    "        ### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluation (4 points)\n",
    "Re-load the best model and evaluate its predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the best model\n",
    "### YOUR CODE\n",
    "\n",
    "# Evaluate\n",
    "### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful tool to analyze your model's performance on the different classes is the confusion matrix (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). Computes its entries for your model and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively it can be useful to plot the problematic samples as well as the predicted and ground truth classes. Can you do so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the misclassified samples\n",
    "### YOUR CODE\n",
    "\n",
    "# Plot the misclassified samples\n",
    "### YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
